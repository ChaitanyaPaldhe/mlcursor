# Common imports
import pandas as pd
import numpy as np

# Framework-specific imports
{% if framework == "pytorch" %}
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
{% elif framework == "tensorflow" %}
import tensorflow as tf
from tensorflow import keras
from sklearn.model_selection import train_test_split
{% elif framework == "sklearn" %}
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder
{% elif framework == "xgboost" %}
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import LabelEncoder
{% elif framework == "lightgbm" %}
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import LabelEncoder
{% elif framework == "catboost" %}
from catboost import CatBoostClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import LabelEncoder
{% endif %}

# Config from prompt
model_name = "{{ model }}"
dataset = "{{ dataset }}"
optimizer = "{{ optimizer }}"
lr = {{ learning_rate | default(0.001) | float }}
epochs = {{ epochs | default(10) }}

print(f"Training {model_name} on {dataset} for {epochs} epochs using {{ framework }}...")

# Generic tabular dataset loading logic (CSV assumed)
try:
    df = pd.read_csv(f"data/{dataset}.csv")
except Exception as e:
    import seaborn as sns
    df = sns.load_dataset(dataset).dropna()

# Preprocessing
label_encoders = {}
for col in df.select_dtypes(include=["object", "category"]).columns:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col].astype(str))
    label_encoders[col] = le

X = df.drop(columns=[df.columns[-1]])
y = df[df.columns[-1]]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Training per framework
{% if framework == "xgboost" %}
model = xgb.XGBClassifier(max_depth={{ max_depth | default(3) }}, learning_rate=lr, n_estimators=epochs)
model.fit(X_train, y_train)
print("Accuracy:", accuracy_score(y_test, model.predict(X_test)))
{% elif framework == "sklearn" %}
model = RandomForestClassifier(n_estimators=epochs)
model.fit(X_train, y_train)
print("Accuracy:", accuracy_score(y_test, model.predict(X_test)))
{% elif framework == "lightgbm" %}
model = lgb.LGBMClassifier(n_estimators=epochs, learning_rate=lr)
model.fit(X_train, y_train)
print("Accuracy:", accuracy_score(y_test, model.predict(X_test)))
{% elif framework == "catboost" %}
model = CatBoostClassifier(iterations=epochs, learning_rate=lr, verbose=0, logging_level='Silent', train_dir='outputs/.catboost')
model.fit(X_train, y_train)
print("Accuracy:", accuracy_score(y_test, model.predict(X_test)))
{% elif framework == "tensorflow" %}
model = keras.Sequential([
    keras.layers.Dense(64, activation='relu'),
    keras.layers.Dense(1, activation='sigmoid')
])
model.compile(optimizer=keras.optimizers.Adam(learning_rate=lr), loss='binary_crossentropy', metrics=['accuracy'])
model.fit(X_train, y_train, epochs=epochs, validation_split=0.2)
{% elif framework == "pytorch" %}
X_tensor = torch.tensor(X_train.values, dtype=torch.float32)
y_tensor = torch.tensor(y_train.values, dtype=torch.float32).unsqueeze(1)
dataset = TensorDataset(X_tensor, y_tensor)
dataloader = DataLoader(dataset, batch_size=32, shuffle=True)

model = nn.Sequential(
    nn.Linear(X.shape[1], 64),
    nn.ReLU(),
    nn.Linear(64, 1),
    nn.Sigmoid()
)

criterion = nn.BCELoss()
optimizer = optim.Adam(model.parameters(), lr=lr)

for epoch in range(epochs):
    for xb, yb in dataloader:
        pred = model(xb)
        loss = criterion(pred, yb)
        loss.backward()
        optimizer.step()
        optimizer.zero_grad()
    print(f"Epoch {epoch+1}: loss = {loss.item():.4f}")
{% endif %}


