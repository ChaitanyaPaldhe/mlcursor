ğŸ§  MLCursor CLI â€” AI-Powered ML Developer in Your Terminal
MLCursor is a blazing-fast, privacy-first CLI tool that turns plain English into working machine learning code. Itâ€™s like Cursor, but for your terminal â€” built specifically for training, tuning, and automating ML workflows with just one command.

ğŸš€ What It Does
ğŸ§¾ Understand prompts like:

"Train an XGBoost classifier on the Titanic dataset with 50 epochs and max_depth 4"

âš™ï¸ Auto-generates full training scripts using:

PyTorch

Scikit-learn

XGBoost

LightGBM

CatBoost

TensorFlow
(More to come!)

ğŸ“¦ Auto-installs missing libraries so you donâ€™t have to.

ğŸ§ª Fully local â€” runs entirely on your system using models from Ollama (e.g. qwen2.5-coder:3b).

ğŸ—‚ï¸ Keeps output scripts in a clean outputs/ folder so you can inspect or reuse.

ğŸ› ï¸ Quickstart
1. âš™ï¸ Install Dependencies
bash
Copy
Edit
pip install typer jinja2 pandas scikit-learn
Also install Ollama: https://ollama.com

2. ğŸ§  Pull a local model
bash
Copy
Edit
ollama pull qwen2.5-coder:3b
3. ğŸ Run your first ML pipeline:
bash
Copy
Edit
python cli.py train "Train a RandomForestClassifier on the penguins dataset for 20 epochs"
Thatâ€™s it. A training script will be:

Autogenerated âœï¸

Auto-filled with dataset logic ğŸ“Š

Auto-installed with dependencies ğŸ”§

And run instantly âš¡

ğŸ§± Project Structure
graphql
Copy
Edit
mlcursor/
â”œâ”€â”€ cli.py                  # Typer CLI entry
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ train.py            # Training logic
â”‚   â”œâ”€â”€ tune.py             # (coming soon)
â”‚   â”œâ”€â”€ deps.py             # Dependency handler
â”‚   â”œâ”€â”€ llm_handler.py      # Query local LLMs
â”‚   â””â”€â”€ logs.py             # (coming soon)
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ train_template.py.j2  # Jinja2 template for ML training
â”œâ”€â”€ outputs/                # Auto-generated training scripts
â”œâ”€â”€ data/                   # Place custom CSVs here
â”œâ”€â”€ config.yaml
â””â”€â”€ README.md
ğŸ’¡ Why MLCursor?
ğŸ§  AI-native workflow â€” generate/train/tune in one line

ğŸ” Privacy-first â€” no cloud/OpenAI/Gemini needed

ğŸ–¥ï¸ Terminal-first â€” perfect for devs who live in CLI

ğŸ› ï¸ Framework-agnostic â€” supports every major ML framework

âœ¨ Extendable â€” more modes coming soon: tune, eval, deploy

ğŸ›£ï¸ Roadmap
ğŸ” Hyperparameter Tuning with Optuna / Ray Tune

ğŸ“¦ Plugin system (e.g., mlcursor plugins)

â˜ï¸ Optional API keys for cloud models (Gemini, GPT-4)

ğŸ–¼ï¸ Image/Text dataset support

ğŸ§© Modular support for any LLM backend

ğŸ’» VS Code Extension (future)

âœ¨ Demo Prompt Ideas
bash
Copy
Edit
python cli.py train "Train a LightGBM model on Titanic for 100 epochs"
python cli.py train "Train ResNet on CIFAR10 using PyTorch"
python cli.py train "Use CatBoost on my data/bank.csv file"
ğŸ’¬ Want to Contribute?
This is just phase 1. If youâ€™re into:

open-source ML tools ğŸ§ª

CLI-first AI interfaces ğŸ¤–

blazing fast dev workflows âš¡

...you're welcome to join the mission.

ğŸ§ª Built With
Typer

Jinja2

Ollama + qwen2.5-coder:3b

ğŸ’¥ Python 3.10+

ğŸ§  Author
Made with â¤ï¸ by Chaitanya Paldhe
â€œAI tools shouldnâ€™t just assist â€” they should do the boring parts for you.â€