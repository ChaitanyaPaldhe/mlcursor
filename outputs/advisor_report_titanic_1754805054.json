{
  "dataset_profile": {
    "n_samples": 182,
    "n_features": 14,
    "target_type": "binary_classification",
    "n_classes": 2,
    "missing_percentage": 0.0,
    "duplicate_percentage": 0.5494505494505495,
    "numerical_features": 6,
    "categorical_features": 7,
    "high_cardinality_features": 0,
    "class_imbalance_ratio": 0.75,
    "feature_correlation_max": 0.3885402355623782,
    "target_skewness": null,
    "complexity": "simple",
    "estimated_training_time": "very_fast",
    "top_features": [
      "sibsp",
      "fare",
      "parch",
      "age",
      "alive",
      "embarked",
      "adult_male",
      "who",
      "class",
      "deck"
    ],
    "feature_importance_scores": {
      "survived": 0.0,
      "pclass": 0.0,
      "sex": 0.0,
      "age": 0.07188271911164379,
      "sibsp": 0.31250538939158945,
      "parch": 0.24059406391210802,
      "fare": 0.2871433478487835,
      "embarked": 0.04733802370547546,
      "class": 0.03184644167870676,
      "who": 0.0334841577911702,
      "adult_male": 0.03822395939587153,
      "deck": 0.023968645920292797,
      "embark_town": 0.02350443970705629,
      "alive": 0.053032287442600134
    }
  },
  "model_recommendations": [
    {
      "model_name": "random_forest",
      "confidence": 1.0,
      "reasoning": [
        "Good fit for dataset size (182 samples)",
        "Handles simple datasets well",
        "Native support for categorical features"
      ],
      "expected_performance_range": [
        0.75,
        0.95
      ],
      "training_time_estimate": "medium",
      "memory_requirements": "medium",
      "hyperparameter_suggestions": {
        "n_estimators": 100,
        "max_depth": 10,
        "min_samples_split": 5,
        "class_weight": null
      },
      "pros": [
        "Handles mixed data types",
        "Built-in feature importance",
        "Robust to outliers"
      ],
      "cons": [
        "Can overfit with small datasets",
        "Less interpretable than single trees"
      ]
    },
    {
      "model_name": "logistic_regression",
      "confidence": 1.0,
      "reasoning": [
        "Good fit for dataset size (182 samples)",
        "Handles simple datasets well"
      ],
      "expected_performance_range": [
        0.75,
        0.95
      ],
      "training_time_estimate": "fast",
      "memory_requirements": "low",
      "hyperparameter_suggestions": {
        "C": 1.0,
        "max_iter": 1000,
        "class_weight": null
      },
      "pros": [
        "Fast training",
        "Interpretable",
        "Probabilistic output"
      ],
      "cons": [
        "Assumes linear relationships",
        "Sensitive to outliers"
      ]
    },
    {
      "model_name": "svm",
      "confidence": 0.7,
      "reasoning": [
        "Good fit for dataset size (182 samples)"
      ],
      "expected_performance_range": [
        0.75,
        0.95
      ],
      "training_time_estimate": "slow",
      "memory_requirements": "medium",
      "hyperparameter_suggestions": {},
      "pros": [
        "Effective in high dimensions",
        "Memory efficient"
      ],
      "cons": [
        "Slow on large datasets",
        "Requires feature scaling"
      ]
    },
    {
      "model_name": "xgboost",
      "confidence": 0.4,
      "reasoning": [
        "Native support for categorical features"
      ],
      "expected_performance_range": [
        0.75,
        0.95
      ],
      "training_time_estimate": "medium",
      "memory_requirements": "medium",
      "hyperparameter_suggestions": {
        "n_estimators": 100,
        "learning_rate": 0.1,
        "max_depth": 3,
        "subsample": 1.0,
        "colsample_bytree": 1.0
      },
      "pros": [
        "Excellent performance",
        "Handles imbalance well",
        "Built-in regularization"
      ],
      "cons": [
        "Many hyperparameters",
        "Less interpretable",
        "Can overfit"
      ]
    }
  ],
  "preprocessing_recommendations": [
    {
      "step": "Encode Categorical Features",
      "reasoning": "Standard categorical encoding needed.",
      "code_snippet": "from sklearn.preprocessing import LabelEncoder, OneHotEncoder",
      "priority": 1
    },
    {
      "step": "Scale Numerical Features",
      "reasoning": "Numerical features may benefit from scaling for certain models.",
      "code_snippet": "from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()",
      "priority": 2
    }
  ],
  "feature_engineering_suggestions": [
    "Consider polynomial features for non-linear relationships",
    "Create interaction features between important variables",
    "Apply text preprocessing: TF-IDF, word embeddings",
    "Consider binning continuous variables for tree-based models"
  ],
  "training_strategy": {
    "cv_strategy": "StratifiedKFold with 5 folds",
    "validation": "Use cross-validation only (small dataset)",
    "hyperparameter_tuning": "Grid search with 3-fold CV"
  },
  "evaluation_strategy": {
    "primary_metric": "Accuracy",
    "additional_metrics": "F1-score, AUC-ROC"
  },
  "metadata": {
    "dataset_name": "titanic",
    "generated_at": "2025-08-10 11:20:54",
    "version": "1.0"
  }
}