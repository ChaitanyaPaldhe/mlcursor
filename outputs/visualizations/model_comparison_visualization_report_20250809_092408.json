{
  "timestamp": "20250809_092408",
  "model_info": {
    "timestamp": "2025-08-09 09:24:09",
    "prompt": "dataset: penguins",
    "models_compared": [
      "random_forest",
      "xgboost",
      "lightgbm"
    ],
    "comparison_type": "cross_validation",
    "cv_folds": 5,
    "results": {
      "random_forest": {
        "status": "success",
        "accuracy": 0.8982,
        "std_dev": 0.0433,
        "training_time": 54.741610527038574,
        "framework": "sklearn",
        "output": "[TRAIN] Received prompt: model: random_forest dataset: penguins\n[CONFIG] Extracting from prompt: model: random_forest dataset: penguins\n[SUCCESS] LLM extracted config: {'framework': 'sklearn', 'model': 'RandomForestClassifier', 'dataset': 'penguins', 'optimizer': 'adam', 'learning_rate': 0.001, 'epochs': 10, 'batch_size': 32, 'task_type': 'classification', 'use_cv': False, 'cv_folds': 5, 'cv_type': 'auto', 'other_params': {'n_estimators': 100}}\n[CV CONFIG] Applying CLI CV settings: {'use_cv': True, 'cv_folds': 5, 'cv_type': 'auto'}\n[REGISTRY] Applied model config for random_forest\n[FINAL CONFIG] CV: True, Folds: 5, Type: auto\n[PARSED CONFIG]:\n{\n  \"framework\": \"sklearn\",\n  \"model\": \"random_forest\",\n  \"dataset\": \"penguins\",\n  \"optimizer\": \"adam\",\n  \"learning_rate\": 0.001,\n  \"epochs\": 10,\n  \"batch_size\": 32,\n  \"task_type\": \"classification\",\n  \"use_cv\": true,\n  \"cv_folds\": 5,\n  \"cv_type\": \"auto\",\n  \"other_params\": {\n    \"n_estimators\": 100,\n    \"random_state\": 42,\n    \"max_depth\": null\n  },\n  \"model_config\": {\n    \"framework\": \"sklearn\",\n    \"class\": \"RandomForestClassifier\",\n    \"import\": \"from sklearn.ensemble import RandomForestClassifier\",\n    \"default_params\": {\n      \"n_estimators\": 100,\n      \"random_state\": 42,\n      \"max_depth\": null\n    }\n  }\n}\n[SCRIPT GENERATED]: outputs/train_random_forest_cv_d08962.py\n\ud83d\udce6 Checking dependencies: seaborn, core, pandas, sklearn, numpy, traceback\n\u2705 All dependencies are already installed\n[EXECUTING] Running random_forest training with 5-fold CV...\n\ud83c\udfa8 Visualizations enabled\nTraining random_forest on penguins dataset\nTask type: classification\nUsing 5-fold cross-validation (auto)\nFramework: sklearn\n[SUCCESS] Loaded dataset from data/penguins.csv\nDataset shape: (333, 7)\nDataset columns: ['species', 'island', 'bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g', 'sex']\nFeatures shape: (333, 6)\nTarget shape: (333,)\nClasses: [0, 1]\n[SUCCESS] Using StratifiedKFold with 5 folds\n[SUCCESS] Model parameters: {'n_estimators': 100, 'random_state': 42, 'max_depth': None}\n\n[INFO] Starting 5-fold cross-validation...\n\n[RESULTS] Cross-Validation Results:\nIndividual fold scores: ['0.8358', '0.8806', '0.8806', '0.9545', '0.9394']\nMean CV Accuracy: 0.8982 \u00b1 0.0433\n\n[METRICS] Additional CV Metrics:\nAccuracy: 0.8982 \u00b1 0.0433\nPrecision Macro: 0.9048 \u00b1 0.0378\nRecall Macro: 0.8986 \u00b1 0.0428\nF1 Macro: 0.8976 \u00b1 0.0440\n\n[INFO] Training final model on full dataset...\n\n[SUCCESS] Training completed successfully!\n\n============================================================\n\ud83c\udfa8 GENERATING VISUALIZATIONS\n============================================================\n\n\ud83c\udfa8 Generating visualizations for random_forest...\n\ud83d\udcca Saved plot: outputs/visualizations\\random_forest_feature_importance_20250809_092343.png\n\ud83d\udcca Saved plot: outputs/visualizations\\random_forest_cv_scores_20250809_092343.png\n\ud83d\udcca Saved plot: outputs/visualizations\\random_forest_confusion_matrix_20250809_092343.png\n\u2705 Generated 3 visualizations\n\ud83d\udccb Visualization summary saved: outputs/visualizations\\random_forest_visualization_report_20250809_092343.json\n\n\u2705 Visualization complete! Generated 3 plots\n\ud83d\udcc1 Plots saved in: outputs/visualizations\n\ud83d\udccb Summary report: outputs/visualizations\\random_forest_visualization_report_20250809_092343.json\n\n\ud83d\udcbe Model info saved to outputs/model_info_random_forest_cv.json\n\n\ud83c\udf89 Training and visualization pipeline completed successfully!\n\n",
        "cross_validation": true,
        "cv_folds": 5
      },
      "xgboost": {
        "status": "success",
        "accuracy": 0.8951,
        "std_dev": 0.0451,
        "training_time": 13.43671727180481,
        "framework": "xgboost",
        "output": "[TRAIN] Received prompt: model: xgboost dataset: penguins\n[CONFIG] Extracting from prompt: model: xgboost dataset: penguins\n[SUCCESS] LLM extracted config: {'framework': 'xgboost', 'model': 'XGBClassifier', 'dataset': 'penguins', 'optimizer': 'adam|sgd|rmsprop', 'learning_rate': 0.01, 'epochs': 200, 'batch_size': 32, 'task_type': 'classification', 'use_cv': False, 'cv_folds': 5, 'cv_type': 'auto', 'other_params': {'eval_metric': 'logloss'}}\n[CV CONFIG] Applying CLI CV settings: {'use_cv': True, 'cv_folds': 5, 'cv_type': 'auto'}\n[REGISTRY] Applied model config for xgboost\n[FINAL CONFIG] CV: True, Folds: 5, Type: auto\n[PARSED CONFIG]:\n{\n  \"framework\": \"xgboost\",\n  \"model\": \"xgboost\",\n  \"dataset\": \"penguins\",\n  \"optimizer\": \"adam|sgd|rmsprop\",\n  \"learning_rate\": 0.01,\n  \"epochs\": 200,\n  \"batch_size\": 32,\n  \"task_type\": \"classification\",\n  \"use_cv\": true,\n  \"cv_folds\": 5,\n  \"cv_type\": \"auto\",\n  \"other_params\": {\n    \"eval_metric\": \"logloss\",\n    \"max_depth\": 3,\n    \"learning_rate\": 0.1,\n    \"n_estimators\": 100,\n    \"random_state\": 42\n  },\n  \"model_config\": {\n    \"framework\": \"xgboost\",\n    \"class\": \"XGBClassifier\",\n    \"import\": \"import xgboost as xgb\",\n    \"default_params\": {\n      \"max_depth\": 3,\n      \"learning_rate\": 0.1,\n      \"n_estimators\": 100,\n      \"random_state\": 42\n    }\n  }\n}\n[SCRIPT GENERATED]: outputs/train_xgboost_cv_d36bf6.py\n\ud83d\udce6 Checking dependencies: seaborn, core, pandas, sklearn, numpy, traceback, xgboost\n\u2705 All dependencies are already installed\n[EXECUTING] Running xgboost training with 5-fold CV...\n\ud83c\udfa8 Visualizations enabled\nTraining xgboost on penguins dataset\nTask type: classification\nUsing 5-fold cross-validation (auto)\nFramework: xgboost\n[SUCCESS] Loaded dataset from data/penguins.csv\nDataset shape: (333, 7)\nDataset columns: ['species', 'island', 'bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g', 'sex']\nFeatures shape: (333, 6)\nTarget shape: (333,)\nClasses: [0, 1]\n[SUCCESS] Using StratifiedKFold with 5 folds\n[SUCCESS] XGBoost parameters: {'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 200, 'random_state': 42, 'objective': 'binary:logistic', 'eval_metric': 'logloss'}\n\n[INFO] Starting 5-fold cross-validation...\nMean CV Accuracy: 0.8951 \u00b1 0.0451\n\n[SUCCESS] Training completed successfully!\n\n============================================================\n\ud83c\udfa8 GENERATING VISUALIZATIONS\n============================================================\n\n\ud83c\udfa8 Generating visualizations for xgboost...\n\ud83d\udcca Saved plot: outputs/visualizations\\xgboost_feature_importance_20250809_092358.png\n\ud83d\udcca Saved plot: outputs/visualizations\\xgboost_cv_scores_20250809_092358.png\n\ud83d\udcca Saved plot: outputs/visualizations\\xgboost_confusion_matrix_20250809_092358.png\n\u2705 Generated 3 visualizations\n\ud83d\udccb Visualization summary saved: outputs/visualizations\\xgboost_visualization_report_20250809_092358.json\n\n\u2705 Visualization complete! Generated 3 plots\n\ud83d\udcc1 Plots saved in: outputs/visualizations\n\ud83d\udccb Summary report: outputs/visualizations\\xgboost_visualization_report_20250809_092358.json\n\n\ud83d\udcbe Model info saved to outputs/model_info_xgboost_cv.json\n\n\ud83c\udf89 Training and visualization pipeline completed successfully!\n\n",
        "cross_validation": true,
        "cv_folds": 5
      },
      "lightgbm": {
        "status": "success",
        "accuracy": 0.0,
        "std_dev": 0.0,
        "training_time": 7.344568490982056,
        "framework": "lightgbm",
        "output": "[TRAIN] Received prompt: model: lightgbm dataset: penguins\n[CONFIG] Extracting from prompt: model: lightgbm dataset: penguins\n[SUCCESS] LLM extracted config: {'framework': 'sklearn', 'model': 'lightgbm', 'dataset': 'penguins', 'optimizer': 'adam', 'learning_rate': 0.1, 'epochs': 25, 'batch_size': 64, 'task_type': 'regression', 'use_cv': False, 'cv_folds': 3, 'cv_type': 'auto', 'other_params': {'num_leaves': 31, 'objective': 'rmse'}}\n[CV CONFIG] Applying CLI CV settings: {'use_cv': True, 'cv_folds': 5, 'cv_type': 'auto'}\n[REGISTRY] Applied model config for lightgbm\n[FINAL CONFIG] CV: True, Folds: 5, Type: auto\n[PARSED CONFIG]:\n{\n  \"framework\": \"sklearn\",\n  \"model\": \"lightgbm\",\n  \"dataset\": \"penguins\",\n  \"optimizer\": \"adam\",\n  \"learning_rate\": 0.1,\n  \"epochs\": 25,\n  \"batch_size\": 64,\n  \"task_type\": \"regression\",\n  \"use_cv\": true,\n  \"cv_folds\": 5,\n  \"cv_type\": \"auto\",\n  \"other_params\": {\n    \"num_leaves\": 31,\n    \"objective\": \"rmse\",\n    \"n_estimators\": 100,\n    \"learning_rate\": 0.1,\n    \"random_state\": 42\n  },\n  \"model_config\": {\n    \"framework\": \"lightgbm\",\n    \"class\": \"LGBMClassifier\",\n    \"import\": \"import lightgbm as lgb\",\n    \"default_params\": {\n      \"n_estimators\": 100,\n      \"learning_rate\": 0.1,\n      \"random_state\": 42\n    }\n  }\n}\n[SCRIPT GENERATED]: outputs/train_lightgbm_cv_f9b3c3.py\n\ud83d\udce6 Checking dependencies: seaborn, core, pandas, sklearn, lightgbm, numpy, traceback\n\u2705 All dependencies are already installed\n[EXECUTING] Running lightgbm training with 5-fold CV...\nERROR: Error during script execution:\nSTDOUT: \ud83c\udfa8 Visualizations enabled\nTraining lightgbm on penguins dataset\nTask type: regression\nUsing 5-fold cross-validation (auto)\nFramework: sklearn\n[SUCCESS] Loaded dataset from data/penguins.csv\nDataset shape: (333, 7)\nDataset columns: ['species', 'island', 'bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g', 'sex']\nFeatures shape: (333, 6)\nTarget shape: (333,)\nTarget range: [0.000, 1.000]\n[SUCCESS] Using KFold with 5 folds\n[SUCCESS] Model parameters: {'n_estimators': 100, 'learning_rate': 0.1, 'random_state': 42}\n\nSTDERR: Traceback (most recent call last):\n  File \"D:\\mlcursor\\outputs\\train_lightgbm_cv_f9b3c3.py\", line 180, in <module>\n    model = LGBMClassifier(**model_params)\n            ^^^^^^^^^^^^^^\nNameError: name 'LGBMClassifier' is not defined\n\nReturn code: 1\n",
        "cross_validation": true,
        "cv_folds": 5
      }
    },
    "summary": {
      "total_models": 3,
      "successful_models": 3,
      "best_model": "random_forest",
      "frameworks_tested": [
        "xgboost",
        "sklearn",
        "lightgbm"
      ]
    }
  },
  "generated_plots": [
    "outputs/visualizations\\comparison_model_comparison_20250809_092408.png"
  ],
  "plot_descriptions": {
    "confusion_matrix": "Shows classification accuracy per class",
    "feature_importance": "Displays most influential features",
    "cv_scores": "Cross-validation performance distribution",
    "learning_curves": "Training progress over epochs",
    "hyperparameter_importance": "Impact of different hyperparameters",
    "optimization_history": "Hyperparameter tuning progress",
    "model_comparison": "Performance comparison between models",
    "regression_results": "Actual vs predicted values for regression"
  }
}